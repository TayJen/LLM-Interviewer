{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4581d70b-b6d6-44d8-bb6a-927878f84bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    chunk_size=1,\n",
    "    dimensions=1024,\n",
    "    show_progress_bar=False\n",
    ")\n",
    "\n",
    "vectore_store_yandex = Chroma(\n",
    "    collection_name=\"ml_yandex_handbook\",\n",
    "    embedding_function=embeddings,\n",
    "    persist_directory=\"./chroma_yandex_db\"\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34d1d88b-fb5a-4786-a700-d6f9d0f64d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: Что такое глубинное обучение и как оно связано с нейронными сетями?  \n",
      "A: Глубинное обучение — это область машинного обучения, основанная на нейронных сетях, которая стремится к обучению представлений объектов на основе данных. Нейронные сети, начиная с 2012 года, становятся стандартом в различных приложениях благодаря своей способности обучаться на больших объемах данных и автоматизировать процесс отбора признаков.\n",
      "\n",
      "Q: Какие две ключевые идеи лежат в основе глубинного обучения?  \n",
      "A: Первая идея — это переход к end-to-end обучению всей системы, что позволяет обучать все слои нейросети одновременно. Вторая идея — это обучение представлений объектов, что позволяет автоматически извлекать информативные признаки из данных, часто неразмеченных.\n",
      "\n",
      "Q: Почему современные нейронные сети сложнее своих предшественников?  \n",
      "A: Современные нейронные сети значительно сложнее из-за роста производительности компьютеров, увеличения объемов доступных данных и потребностей индустрии, что привело к более сложным архитектурам и методам обучения.\n",
      "\n",
      "Q: Какова роль обратного распространения ошибки в обучении нейронных сетей?  \n",
      "A: Обратное распространение ошибки позволяет эффективно вычислять градиенты для всех параметров нейронной сети, что делает возможным использование градиентного спуска для оптимизации весов и обучения модели.\n",
      "\n",
      "Q: Что такое регуляризация в контексте нейронных сетей?  \n",
      "A: Регуляризация — это набор техник, направленных на предотвращение переобучения модели, включая добавление штрафов к функции потерь, изменение структуры сети и аугментацию данных.\n",
      "\n",
      "Q: Как работает метод dropout и какую роль он играет в обучении нейронных сетей?  \n",
      "A: Метод dropout случайным образом \"выключает\" некоторые нейроны во время обучения, что помогает предотвратить переобучение, заставляя модель использовать различные подмножества параметров и улучшая её обобщающую способность.\n",
      "\n",
      "Q: Что такое batch normalization и как она влияет на обучение нейронных сетей?  \n",
      "A: Batch normalization нормализует выходы слоев нейронной сети, приводя их к нулевому среднему и единичной дисперсии. Это ускоряет обучение и улучшает сходимость, позволяя использовать более высокие значения темпа обучения.\n",
      "\n",
      "Q: Каковы основные преимущества использования ансамблей в машинном обучении?  \n",
      "A: Ансамбли, такие как бэггинг и бустинг, позволяют уменьшить разброс и смещение предсказаний, комбинируя результаты нескольких моделей, что часто приводит к улучшению качества предсказаний по сравнению с отдельными моделями.\n",
      "\n",
      "Q: В чем заключается принцип работы случайного леса?  \n",
      "A: Случайный лес использует множество решающих деревьев, обученных на случайных подвыборках данных и случайных подмножествах признаков, что позволяет уменьшить корреляцию между деревьями и, как следствие, улучшить обобщающую способность ансамбля.\n",
      "\n",
      "Q: Какова роль смещения и разброса в оценке качества моделей машинного обучения?  \n",
      "A: Смещение отражает систематическую ошибку модели, а разброс — чувствительность модели к изменениям в обучающей выборке. Оптимизация модели включает в себя балансировку между этими двумя компонентами для достижения наилучшего качества предсказаний.\n"
     ]
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever_yandex = vectore_store_yandex.as_retriever()\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Generate the questions for the interviewee based on the selected topic of the interview:\n",
    "{input}\n",
    "And provided context (it's text of the book):\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Генерировать надо на русском. Нужно сгенерировать как вопрос, так и ответ на этот вопрос, используя лишь приведенную информацию. В формате\n",
    "\n",
    "Q: ...\n",
    "A: ...\n",
    "\n",
    "Всего нужно сгенерировать 10 вопросов.\n",
    "\"\"\")\n",
    "\n",
    "# Create a retrieval chain to answer questions\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "retrieval_chain = create_retrieval_chain(retriever_yandex, document_chain)\n",
    "response = retrieval_chain.invoke({\"input\": \"Глубокое обучение\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19784d9b-404d-453f-a528-9965a5f5ff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions:\n",
      "10\n",
      "\n",
      "Answers:\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "generated_questions = response[\"answer\"]\n",
    "\n",
    "# Regular expressions to match questions and answers\n",
    "questions = re.findall(r'Q: (.*?)\\n', generated_questions, re.DOTALL)\n",
    "answers = re.findall(r'A: (.*?)(?:\\nQ:|\\n?$)', generated_questions, re.DOTALL)\n",
    "\n",
    "# Output results\n",
    "print(\"Questions:\")\n",
    "print(len(questions))\n",
    "print(\"\\nAnswers:\")\n",
    "print(len(answers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c6d44fd-2c81-4ccb-a29a-c2fbc6d83fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Что такое глубинное обучение и как оно связано с нейронными сетями?\n",
      "Глубинное обучение — это область машинного обучения, основанная на нейронных сетях, которая стремится к обучению представлений объектов на основе данных. Нейронные сети, начиная с 2012 года, становятся стандартом в различных приложениях благодаря своей способности обучаться на больших объемах данных и автоматизировать процесс отбора признаков.\n",
      "\n",
      "Какие две ключевые идеи лежат в основе глубинного обучения?\n",
      "Первая идея — это переход к end-to-end обучению всей системы, что позволяет обучать все слои нейросети одновременно. Вторая идея — это обучение представлений объектов, что позволяет автоматически извлекать информативные признаки из данных, часто неразмеченных.\n",
      "\n",
      "Почему современные нейронные сети сложнее своих предшественников?\n",
      "Современные нейронные сети значительно сложнее из-за роста производительности компьютеров, увеличения объемов доступных данных и потребностей индустрии, что привело к более сложным архитектурам и методам обучения.\n",
      "\n",
      "Какова роль обратного распространения ошибки в обучении нейронных сетей?\n",
      "Обратное распространение ошибки позволяет эффективно вычислять градиенты для всех параметров нейронной сети, что делает возможным использование градиентного спуска для оптимизации весов и обучения модели.\n",
      "\n",
      "Что такое регуляризация в контексте нейронных сетей?\n",
      "Регуляризация — это набор техник, направленных на предотвращение переобучения модели, включая добавление штрафов к функции потерь, изменение структуры сети и аугментацию данных.\n",
      "\n",
      "Как работает метод dropout и какую роль он играет в обучении нейронных сетей?\n",
      "Метод dropout случайным образом \"выключает\" некоторые нейроны во время обучения, что помогает предотвратить переобучение, заставляя модель использовать различные подмножества параметров и улучшая её обобщающую способность.\n",
      "\n",
      "Что такое batch normalization и как она влияет на обучение нейронных сетей?\n",
      "Batch normalization нормализует выходы слоев нейронной сети, приводя их к нулевому среднему и единичной дисперсии. Это ускоряет обучение и улучшает сходимость, позволяя использовать более высокие значения темпа обучения.\n",
      "\n",
      "Каковы основные преимущества использования ансамблей в машинном обучении?\n",
      "Ансамбли, такие как бэггинг и бустинг, позволяют уменьшить разброс и смещение предсказаний, комбинируя результаты нескольких моделей, что часто приводит к улучшению качества предсказаний по сравнению с отдельными моделями.\n",
      "\n",
      "В чем заключается принцип работы случайного леса?\n",
      "Случайный лес использует множество решающих деревьев, обученных на случайных подвыборках данных и случайных подмножествах признаков, что позволяет уменьшить корреляцию между деревьями и, как следствие, улучшить обобщающую способность ансамбля.\n",
      "\n",
      "Какова роль смещения и разброса в оценке качества моделей машинного обучения?\n",
      "Смещение отражает систематическую ошибку модели, а разброс — чувствительность модели к изменениям в обучающей выборке. Оптимизация модели включает в себя балансировку между этими двумя компонентами для достижения наилучшего качества предсказаний.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for question, answer in zip(questions, answers):\n",
    "    print(question.strip())\n",
    "    print(answer.strip())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9c25088-844e-4de4-b1c9-107b99bf5c0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Dropout — это техника регуляризации, при которой случайным образом \"выключаются\" некоторые нейроны во время обучения, что помогает предотвратить переобучение и заставляет модель использовать все доступные параметры, а не полагаться на небольшое подмножество.',\n",
       " 'Dropout - это техника регуляризации нейронных сетей, при которой рандомные нейроны выбрасываются с фиксированной вероятностью')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curr_question = questions[4]\n",
    "curr_answer = answers[4]\n",
    "\n",
    "my_answer = \"Dropout - это техника регуляризации нейронных сетей, при которой рандомные нейроны выбрасываются с фиксированной вероятностью\"\n",
    "curr_answer.strip(), my_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d5aeed6-25ee-47a6-883b-3b77f0d9caa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Grade: 0.7  \\nTips: Ваш ответ правильно определяет, что такое dropout и что это техника регуляризации, но он не совсем полон. Было бы полезно упомянуть, как именно dropout помогает предотвратить переобучение, например, за счет того, что модель становится менее зависимой от конкретных нейронов и вынуждена использовать все доступные параметры. Также стоит отметить, что dropout применяется только во время обучения, а во время тестирования все нейроны используются. Это добавило бы глубины вашему ответу.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Ты помогающий интервьюеру ассистент, который оценивает ответ собеседующего от 0 до 1 (вещественным числом) \" + \\\n",
    "            \"Дан следующий вопрос: {input_question} и вот его истинный ответ: {input_answer}. \" + \\\n",
    "            \"Если что можешь использовать свой предобученный контекст чтобы узнать дополнительные детали для ответа на вопрос.\" + \\\n",
    "            \"Помимо этого нужно помочь собеседуемому понять, почему его оценка справедлива и какие детали еще необходимо упомянуть для полноценного ответа\" + \\\n",
    "            \"Необходимо дать ответ в формате: \\n\\n Grade: ... \\n Tips: ...\",\n",
    "        ),\n",
    "        (\"human\", \"Вот ответ собеседуемого: {input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | answer_llm\n",
    "\n",
    "ai_answer_rate = chain.invoke(\n",
    "    {\n",
    "        \"input_question\": curr_question,\n",
    "        \"input_answer\": curr_answer,\n",
    "        \"input\": my_answer,\n",
    "    }\n",
    ")\n",
    "\n",
    "ai_answer_rate.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46db72c4-108e-49d9-9e44-bc9d71fe1e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 0.7  \n",
      "Tips: Ваш ответ правильно определяет, что такое dropout и что это техника регуляризации, но он не совсем полон. Было бы полезно упомянуть, как именно dropout помогает предотвратить переобучение, например, за счет того, что модель становится менее зависимой от конкретных нейронов и вынуждена использовать все доступные параметры. Также стоит отметить, что dropout применяется только во время обучения, а во время тестирования все нейроны используются. Это добавило бы глубины вашему ответу.\n"
     ]
    }
   ],
   "source": [
    "print(ai_answer_rate.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f0ac0b7-1443-42a1-be60-2626b89c722e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grade: 0.7\n",
      "\n",
      "Tips: Ваш ответ правильно определяет, что такое dropout и что это техника регуляризации, но он не совсем полон. Было бы полезно упомянуть, как именно dropout помогает предотвратить переобучение, например, за счет того, что модель становится менее зависимой от конкретных нейронов и вынуждена использовать все доступные параметры. Также стоит отметить, что dropout применяется только во время обучения, а во время тестирования все нейроны используются. Это добавило бы глубины вашему ответу.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expressions to extract grade and tips\n",
    "grade_match = re.search(r'Grade:\\s([\\d.]+)', ai_answer_rate.content)\n",
    "tips_match = re.search(r'Tips:\\s(.+)', ai_answer_rate.content, re.DOTALL)\n",
    "\n",
    "# Extracting and converting the grade\n",
    "grade = float(grade_match.group(1)) if grade_match else None\n",
    "\n",
    "# Extracting the tips\n",
    "tips = tips_match.group(1).strip() if tips_match else None\n",
    "\n",
    "# Output results\n",
    "print(\"Grade:\", grade)\n",
    "print(\"\\nTips:\", tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3127f4-50cd-4e60-abed-9df38973f5f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6760e10-8ae7-4c5b-8070-1e912791a6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b2d9e4-a499-461e-86fc-be230b339ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_interviewer",
   "language": "python",
   "name": "llm_interviewer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
