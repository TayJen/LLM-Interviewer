{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a3abd6-b025-45a0-8039-9876be8a1ff1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902b89b6-aee6-4154-b66c-a0ef2d86ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594be6e-e614-4816-9b88-c71e49f2bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_QUESTIONS_PARSED = 0\n",
    "PARSING_RESULT_PATH = \"./questions_data/data/\"\n",
    "RAW_PATH = \"./questions_data/raw/\"\n",
    "\n",
    "os.makedirs(PARSING_RESULT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bbbaa-b3da-4aaa-b044-804db45dcb9e",
   "metadata": {},
   "source": [
    "## 1. Data-Science-Interview-Questions-Answers\n",
    "https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcc214b-b364-4359-8d06-d9c35b467d8a",
   "metadata": {},
   "source": [
    "### Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f20a37-06bc-4414-90de-6b888773781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_url = \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/README.md\"\n",
    "\n",
    "# parsed from here already to files\n",
    "# github_questions_urls = [\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Deep%20Learning%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Statistics%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Probability%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Python%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/SQL%20%26%20DB%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Resume%20Based%20Questions.md\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3d5d47-9a79-43cd-bb06-985a9fbbcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_mds_path = os.path.join(RAW_PATH, \"data-science-interview-questions-mds/\")\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers\n",
    "    # Modified regex to handle both \"? ###\" and \"?###\" formats\n",
    "    question_pattern = re.compile(r\"### Q\\d+: (.+)\")\n",
    "    answer_start_pattern = re.compile(r\"Answer:\\s*(.*)\", re.IGNORECASE)\n",
    "    \n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "    \n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "    \n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "    \n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "    \n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions\n",
    "        question_match = question_pattern.match(line)\n",
    "        \n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question,\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "            \n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1)\n",
    "            current_answer = []  # Reset for the new question\n",
    "    \n",
    "        else:\n",
    "            # Match and capture the answer when 'Answer:' keyword is found\n",
    "            answer_match = answer_start_pattern.match(line)\n",
    "            if answer_match:\n",
    "                # Start the answer with any text found on the same line after 'Answer:'\n",
    "                current_answer.append(answer_match.group(1))\n",
    "            elif current_question and current_answer is not None and not question_pattern.match(line):\n",
    "                # Accumulate answer lines (anything after 'Answer:' until next question)\n",
    "                current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "    return qa_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b740ced1-a107-42bd-ad91-95b037f5ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in Machine Learning Interview Questions & Answers for Data Scientists.md\n",
      "machine_learning_interview\n",
      "Successfully parsed 36 questions and answers.\n",
      "\n",
      "Now in Python Interview Questions & Answers for Data Scientists.md\n",
      "python_interview_questions\n",
      "Successfully parsed 14 questions and answers.\n",
      "\n",
      "Now in Probability Interview Questions & Answers for Data Scientists.md\n",
      "probability_interview_questions\n",
      "Successfully parsed 17 questions and answers.\n",
      "\n",
      "Now in Resume Based Questions.md\n",
      "resume_based_questions\n",
      "Successfully parsed 2 questions and answers.\n",
      "\n",
      "Now in Deep Learning Questions & Answers for Data Scientists.md\n",
      "deep_learning_questions\n",
      "Successfully parsed 44 questions and answers.\n",
      "\n",
      "Now in SQL & DB Interview Questions & Answers for Data Scientists.md\n",
      "sql_&_db\n",
      "Successfully parsed 12 questions and answers.\n",
      "\n",
      "Now in Statistics Interview Questions & Answers for Data Scientists.md\n",
      "statistics_interview_questions\n",
      "Successfully parsed 17 questions and answers.\n",
      "\n",
      "Total questions parsed: 142\n"
     ]
    }
   ],
   "source": [
    "for file_name in github_mds_files:\n",
    "    print(f\"Now in {file_name}\")\n",
    "    concept_name = '_'.join(file_name.split('.')[0].split(' ')[:3]).lower()\n",
    "    print(concept_name)\n",
    "\n",
    "    with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "        content = f.read()\n",
    "        qa_list = parse_questions_answers(content)\n",
    "\n",
    "    with open(f\"questions_data/data/1_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "        json.dump(qa_list, f)\n",
    "\n",
    "    print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "    TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2efafe4-d3a1-4232-97e7-1c6cc1e44b56",
   "metadata": {},
   "source": [
    "### Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b80929ab-19a3-47c4-8d6e-9a8bb2702d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloaded pages already to files\n",
    "# medium_question_urls = [\n",
    "#     \"https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e\",\n",
    "#     \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-1-7eddf45cfdf7\",\n",
    "#     \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-2-107244fc4289\",\n",
    "#     \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-3-1e43909131b2\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e85f42d-5db1-4dd2-8ff1-a463da686d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top Large Language Models (LLMs) Interview Questions & Answers _ by Youssef Hosni _ Level Up Coding.html',\n",
       " 'Top Computer Vision Interview Questions & Answers [Part 2] _ by Youssef Hosni _ Level Up Coding.html',\n",
       " 'Top Computer Vision Interview Questions & Answers [Part 3] _ by Youssef Hosni _ Level Up Coding.html',\n",
       " 'Top Computer Vision Interview Questions & Answers [Part 1] _ by Youssef Hosni _ Level Up Coding.html']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_html_path = os.path.join(RAW_PATH, \"data-science-interview-questions-medium/\")\n",
    "medium_html_files = [file_name for file_name in os.listdir(medium_html_path) if file_name.endswith('html')]\n",
    "medium_html_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9578a638-4e8c-4e1c-8295-8900e7e927c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('top_large_language_models', 'top_computer_vision_interview_part_1')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_concept_name(file_name: str) -> str:\n",
    "    main_concept = '_'.join(file_name.split(' ')[:4]).lower()\n",
    "\n",
    "    bracket_splits = file_name.split('[')\n",
    "    if len(bracket_splits) == 1:\n",
    "        return main_concept\n",
    "\n",
    "    part_number = '_'.join(bracket_splits[1].split(']')[0].split(' ')).lower()\n",
    "    return main_concept + '_' + part_number\n",
    "\n",
    "get_concept_name(medium_html_files[0]), get_concept_name(medium_html_files[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32633a5e-af48-4860-a993-889fec2fda1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_questions_answers_from_html(html_content: str):\n",
    "    # Initialize BeautifulSoup with the HTML content\n",
    "    soup = BeautifulSoup(html_content, \"lxml\")\n",
    "    \n",
    "    # Lists to store the extracted questions and answers\n",
    "    qa_list = []\n",
    "    \n",
    "    # Find all sections of the HTML that correspond to questions\n",
    "    question_tags = soup.find_all('h1')  # Assuming questions are in h1 tags\n",
    "    \n",
    "    # Loop through each question and gather all content until the next question\n",
    "    for i, question_tag in enumerate(question_tags):\n",
    "        # Extract the question text\n",
    "        question_text = extract_text_with_formatting(question_tag)\n",
    "        \n",
    "        # Find all the elements between this question and the next question\n",
    "        answer_elements = []\n",
    "        next_question_tag = question_tags[i + 1] if i + 1 < len(question_tags) else None\n",
    "        \n",
    "        # Collect the elements between the current question and the next question\n",
    "        sibling = question_tag.find_next_sibling()\n",
    "        while sibling and sibling != next_question_tag:\n",
    "            answer_elements.append(sibling)\n",
    "            sibling = sibling.find_next_sibling()\n",
    "\n",
    "        # Combine all answer elements into a single formatted string\n",
    "        answer_text = '\\n'.join([extract_text_with_formatting(el) for el in answer_elements])\n",
    "        \n",
    "        # Store the question and answer in the qa_list\n",
    "        qa_list.append({\n",
    "            \"question\": question_text,\n",
    "            \"answer\": answer_text\n",
    "        })\n",
    "    \n",
    "    return qa_list\n",
    "\n",
    "def extract_text_with_formatting(element):\n",
    "    \"\"\" Helper function to extract text from an HTML element, preserving bold and italic. \"\"\"\n",
    "    if element is None:\n",
    "        return ''\n",
    "    \n",
    "    text = \"\"\n",
    "    for content in element.contents:\n",
    "        if content.name == 'strong':\n",
    "            text += f\"**{content.get_text()}**\"  # Markdown format for bold\n",
    "        elif content.name == 'em':\n",
    "            text += f\"*{content.get_text()}*\"  # Markdown format for italics\n",
    "        elif isinstance(content, str):\n",
    "            text += content\n",
    "        else:\n",
    "            text += extract_text_with_formatting(content)  # Recursive call for nested elements\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36c509c5-6c7a-484c-9bfe-dfe7e2f9fb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in Top Large Language Models (LLMs) Interview Questions & Answers _ by Youssef Hosni _ Level Up Coding.html\n",
      "top_large_language_models\n",
      "Successfully parsed 24 questions and answers.\n",
      "\n",
      "Now in Top Computer Vision Interview Questions & Answers [Part 2] _ by Youssef Hosni _ Level Up Coding.html\n",
      "top_computer_vision_interview_part_2\n",
      "Successfully parsed 29 questions and answers.\n",
      "\n",
      "Now in Top Computer Vision Interview Questions & Answers [Part 3] _ by Youssef Hosni _ Level Up Coding.html\n",
      "top_computer_vision_interview_part_3\n",
      "Successfully parsed 23 questions and answers.\n",
      "\n",
      "Now in Top Computer Vision Interview Questions & Answers [Part 1] _ by Youssef Hosni _ Level Up Coding.html\n",
      "top_computer_vision_interview_part_1\n",
      "Successfully parsed 4 questions and answers.\n",
      "\n",
      "Total questions parsed: 222\n"
     ]
    }
   ],
   "source": [
    "for medium_html_file in medium_html_files:\n",
    "    print(f\"Now in {medium_html_file}\")\n",
    "    with open(os.path.join(medium_html_path, medium_html_file), \"r\", encoding=\"utf-8\") as html_f:\n",
    "        html_content = html_f.read()\n",
    "\n",
    "    # Get concept name\n",
    "    concept_name = get_concept_name(medium_html_file)\n",
    "    print(concept_name)\n",
    "\n",
    "    # Parse questions and answers\n",
    "    qa_list = parse_questions_answers_from_html(html_content)\n",
    "\n",
    "    with open(f\"questions_data/data/1_{concept_name}_medium_parsed_questions.json\", 'w') as f:\n",
    "        json.dump(qa_list, f)\n",
    "\n",
    "    print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "    TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cce8d6-504c-4310-9631-d18b814c1cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb694278-306c-4dc4-a265-db06296ecea2",
   "metadata": {},
   "source": [
    "## 2. Data-Science-Interviews\n",
    "\n",
    "https://github.com/alexeygrigorev/data-science-interviews/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c78487-7eb2-4372-bdfe-9cf6d3143d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theory.md']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_mds_path = os.path.join(RAW_PATH, \"data-science-interviews-mds/\")\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "github_mds_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b188a7-b3c7-405b-9eff-b5a7daf34c1b",
   "metadata": {},
   "source": [
    "P.S. Решил дропнуть technical.md, так как там в основном SQL, алгоритмы и просто Python, пока обойдемся без таких практических вопросов и сконцентрируемся на ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c4ff28-e740-40ab-8309-182fb4b4faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers\n",
    "    question_pattern = re.compile(r\"\\*\\*(.+?)\\*\\*\")\n",
    "\n",
    "    # Regular expression to identify section headers (lines that start with \"## \")\n",
    "    section_header_pattern = re.compile(r\"^##\\s+.+\")\n",
    "\n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "\n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "\n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "\n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "\n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions (lines with \"**\" on both sides)\n",
    "        question_match = question_pattern.match(line)\n",
    "\n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question,\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "\n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1).strip()  # Clean up any leading/trailing spaces\n",
    "            current_answer = []  # Reset for the new question\n",
    "\n",
    "        # Skip section headers\n",
    "        elif section_header_pattern.match(line):\n",
    "            # If it's a section header, we skip it and do not add it to the answer\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # Accumulate answer lines (anything after the question)\n",
    "            current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "\n",
    "    return qa_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91537859-4fb1-44f6-9fbf-8bee2f705301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in theory.md\n",
      "theory\n",
      "Successfully parsed 166 questions and answers.\n",
      "\n",
      "Total questions parsed: 308\n"
     ]
    }
   ],
   "source": [
    "for file_name in github_mds_files:\n",
    "    print(f\"Now in {file_name}\")\n",
    "    concept_name = file_name.split('.')[0]\n",
    "    print(concept_name)\n",
    "\n",
    "    with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "        content = f.read()\n",
    "        qa_list = parse_questions_answers(content)\n",
    "\n",
    "    with open(f\"questions_data/data/2_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "        json.dump(qa_list, f)\n",
    "\n",
    "    print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "    TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a49b8-e53d-4bef-a625-67b131c17d4d",
   "metadata": {},
   "source": [
    "## 3. Data-Science-Interview-Questions-And-Answers\n",
    "\n",
    "https://github.com/iamtodor/data-science-interview-questions-and-answers/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d92026b-95fe-42b8-b177-b86b8a58451d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main.md']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_mds_path = os.path.join(RAW_PATH, \"data-science-interview-questions-and-answers-mds/\")\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "github_mds_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7642f7-16f9-407a-9925-afcb242084e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers (e.g., \"## 1. Why do you use feature selection?\")\n",
    "    question_pattern = re.compile(r\"^##\\s*\\d+\\.\\s*(.+)\")\n",
    "    \n",
    "    # Regular expression to identify sub-section headers within the answers (e.g., \"#### Filter Methods\")\n",
    "    subsection_pattern = re.compile(r\"^####\\s*(.+)\")\n",
    "    \n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "    \n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "    \n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "    \n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "    \n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions (lines that start with \"## <number>.\")\n",
    "        question_match = question_pattern.match(line.strip())\n",
    "\n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question.strip(),\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "            \n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1).strip()  # Extract the question text\n",
    "            current_answer = []  # Reset for the new question\n",
    "        \n",
    "        # Match subsection headers (lines that start with \"####\"), these belong to the answer\n",
    "        elif subsection_pattern.match(line.strip()):\n",
    "            # Add subsections as part of the answer (e.g., \"#### Filter Methods\")\n",
    "            current_answer.append(f\"\\n\\n####{subsection_pattern.match(line.strip()).group(1)}\\n\\n\")\n",
    "        \n",
    "        else:\n",
    "            # Accumulate answer lines (anything after the question that isn't a new question header)\n",
    "            current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "    \n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be4839b2-2866-4b43-908b-f7a507811212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in main.md\n",
      "main\n",
      "Successfully parsed 33 questions and answers.\n",
      "\n",
      "Total questions parsed: 341\n"
     ]
    }
   ],
   "source": [
    "TOTAL_QUESTIONS_PARSED = 308\n",
    "\n",
    "file_name = github_mds_files[0]\n",
    "print(f\"Now in {file_name}\")\n",
    "concept_name = file_name.split('.')[0]\n",
    "print(concept_name)\n",
    "\n",
    "with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "    content = f.read()\n",
    "    qa_list = parse_questions_answers(content)\n",
    "\n",
    "with open(f\"questions_data/data/3_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "    json.dump(qa_list, f)\n",
    "\n",
    "print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40479449-b809-4178-a0f8-b3ea1db306c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ec0ef-1c03-4eb2-bf2a-da8df07cac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_interviewer",
   "language": "python",
   "name": "llm_interviewer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
