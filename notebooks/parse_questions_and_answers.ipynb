{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a3abd6-b025-45a0-8039-9876be8a1ff1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902b89b6-aee6-4154-b66c-a0ef2d86ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "# from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594be6e-e614-4816-9b88-c71e49f2bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_QUESTIONS_PARSED = 0\n",
    "PARSING_RESULT_PATH = \"questions_data/data/\"\n",
    "\n",
    "os.makedirs(PARSING_RESULT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7bbbaa-b3da-4aaa-b044-804db45dcb9e",
   "metadata": {},
   "source": [
    "## 1. Data-Science-Interview-Questions-Answers\n",
    "https://github.com/youssefHosni/Data-Science-Interview-Questions-Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f20a37-06bc-4414-90de-6b888773781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main_url = \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/README.md\"\n",
    "\n",
    "# parsed from here already to files\n",
    "# github_questions_urls = [\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Machine%20Learning%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Deep%20Learning%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Statistics%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Probability%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Python%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/SQL%20%26%20DB%20Interview%20Questions%20%26%20Answers%20for%20Data%20Scientists.md\",\n",
    "#     \"https://raw.githubusercontent.com/youssefHosni/Data-Science-Interview-Questions-Answers/refs/heads/main/Resume%20Based%20Questions.md\"\n",
    "# ]\n",
    "\n",
    "medium_question_urls = [\n",
    "    \"https://levelup.gitconnected.com/top-large-language-models-llms-interview-questions-answers-d7b83f94c4e\",\n",
    "    \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-1-7eddf45cfdf7\",\n",
    "    \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-2-107244fc4289\",\n",
    "    \"https://levelup.gitconnected.com/top-computer-vision-interview-questions-answers-part-3-1e43909131b2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3d5d47-9a79-43cd-bb06-985a9fbbcd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_mds_path = \"./questions_data/data-science-interview-questions-mds/\"\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers\n",
    "    # Modified regex to handle both \"? ###\" and \"?###\" formats\n",
    "    question_pattern = re.compile(r\"### Q\\d+: (.+)\")\n",
    "    answer_start_pattern = re.compile(r\"Answer:\\s*(.*)\", re.IGNORECASE)\n",
    "    \n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "    \n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "    \n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "    \n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "    \n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions\n",
    "        question_match = question_pattern.match(line)\n",
    "        \n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question,\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "            \n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1)\n",
    "            current_answer = []  # Reset for the new question\n",
    "    \n",
    "        else:\n",
    "            # Match and capture the answer when 'Answer:' keyword is found\n",
    "            answer_match = answer_start_pattern.match(line)\n",
    "            if answer_match:\n",
    "                # Start the answer with any text found on the same line after 'Answer:'\n",
    "                current_answer.append(answer_match.group(1))\n",
    "            elif current_question and current_answer is not None and not question_pattern.match(line):\n",
    "                # Accumulate answer lines (anything after 'Answer:' until next question)\n",
    "                current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "    return qa_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b740ced1-a107-42bd-ad91-95b037f5ffaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in Machine Learning Interview Questions & Answers for Data Scientists.md\n",
      "machine_learning_interview\n",
      "Successfully parsed 36 questions and answers.\n",
      "\n",
      "Now in Python Interview Questions & Answers for Data Scientists.md\n",
      "python_interview_questions\n",
      "Successfully parsed 14 questions and answers.\n",
      "\n",
      "Now in Probability Interview Questions & Answers for Data Scientists.md\n",
      "probability_interview_questions\n",
      "Successfully parsed 17 questions and answers.\n",
      "\n",
      "Now in Resume Based Questions.md\n",
      "resume_based_questions\n",
      "Successfully parsed 2 questions and answers.\n",
      "\n",
      "Now in Deep Learning Questions & Answers for Data Scientists.md\n",
      "deep_learning_questions\n",
      "Successfully parsed 44 questions and answers.\n",
      "\n",
      "Now in SQL & DB Interview Questions & Answers for Data Scientists.md\n",
      "sql_&_db\n",
      "Successfully parsed 12 questions and answers.\n",
      "\n",
      "Now in Statistics Interview Questions & Answers for Data Scientists.md\n",
      "statistics_interview_questions\n",
      "Successfully parsed 17 questions and answers.\n",
      "\n",
      "Total questions parsed: 142\n"
     ]
    }
   ],
   "source": [
    "for file_name in github_mds_files:\n",
    "    print(f\"Now in {file_name}\")\n",
    "    concept_name = '_'.join(file_name.split('.')[0].split(' ')[:3]).lower()\n",
    "    print(concept_name)\n",
    "\n",
    "    with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "        content = f.read()\n",
    "        qa_list = parse_questions_answers(content)\n",
    "\n",
    "    with open(f\"questions_data/data/1_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "        json.dump(qa_list, f)\n",
    "\n",
    "    print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "    TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb694278-306c-4dc4-a265-db06296ecea2",
   "metadata": {},
   "source": [
    "## 2. Data-Science-Interviews\n",
    "\n",
    "https://github.com/alexeygrigorev/data-science-interviews/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c78487-7eb2-4372-bdfe-9cf6d3143d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['theory.md']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_mds_path = \"./questions_data/data-science-interviews-mds/\"\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "github_mds_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b188a7-b3c7-405b-9eff-b5a7daf34c1b",
   "metadata": {},
   "source": [
    "P.S. Решил дропнуть technical.md, так как там в основном SQL, алгоритмы и просто Python, пока обойдемся без таких практических вопросов и сконцентрируемся на ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c4ff28-e740-40ab-8309-182fb4b4faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers\n",
    "    question_pattern = re.compile(r\"\\*\\*(.+?)\\*\\*\")\n",
    "\n",
    "    # Regular expression to identify section headers (lines that start with \"## \")\n",
    "    section_header_pattern = re.compile(r\"^##\\s+.+\")\n",
    "\n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "\n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "\n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "\n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "\n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions (lines with \"**\" on both sides)\n",
    "        question_match = question_pattern.match(line)\n",
    "\n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question,\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "\n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1).strip()  # Clean up any leading/trailing spaces\n",
    "            current_answer = []  # Reset for the new question\n",
    "\n",
    "        # Skip section headers\n",
    "        elif section_header_pattern.match(line):\n",
    "            # If it's a section header, we skip it and do not add it to the answer\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            # Accumulate answer lines (anything after the question)\n",
    "            current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "\n",
    "    return qa_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91537859-4fb1-44f6-9fbf-8bee2f705301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in theory.md\n",
      "theory\n",
      "Successfully parsed 166 questions and answers.\n",
      "\n",
      "Total questions parsed: 308\n"
     ]
    }
   ],
   "source": [
    "for file_name in github_mds_files:\n",
    "    print(f\"Now in {file_name}\")\n",
    "    concept_name = file_name.split('.')[0]\n",
    "    print(concept_name)\n",
    "\n",
    "    with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "        content = f.read()\n",
    "        qa_list = parse_questions_answers(content)\n",
    "\n",
    "    with open(f\"questions_data/data/2_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "        json.dump(qa_list, f)\n",
    "\n",
    "    print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "    TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "    print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a49b8-e53d-4bef-a625-67b131c17d4d",
   "metadata": {},
   "source": [
    "## 3. Data-Science-Interview-Questions-And-Answers\n",
    "\n",
    "https://github.com/iamtodor/data-science-interview-questions-and-answers/tree/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d92026b-95fe-42b8-b177-b86b8a58451d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['main.md']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_mds_path = \"./questions_data/data-science-interview-questions-and-answers-mds/\"\n",
    "github_mds_files = os.listdir(github_mds_path)\n",
    "\n",
    "github_mds_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce7642f7-16f9-407a-9925-afcb242084e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_questions_answers(content: str) -> list[dict[str, str]]:\n",
    "    # Regular expression to identify question headers (e.g., \"## 1. Why do you use feature selection?\")\n",
    "    question_pattern = re.compile(r\"^##\\s*\\d+\\.\\s*(.+)\")\n",
    "    \n",
    "    # Regular expression to identify sub-section headers within the answers (e.g., \"#### Filter Methods\")\n",
    "    subsection_pattern = re.compile(r\"^####\\s*(.+)\")\n",
    "    \n",
    "    # List to hold the parsed questions and answers\n",
    "    qa_list = []\n",
    "    \n",
    "    current_question = None\n",
    "    current_answer = []\n",
    "    \n",
    "    # Split the content into lines\n",
    "    lines = content.splitlines()\n",
    "    \n",
    "    def clean_answer(answer_lines):\n",
    "        \"\"\" Helper function to clean answer lines \"\"\"\n",
    "        return \"\\n\".join(answer_lines).strip()\n",
    "    \n",
    "    # Loop through each line to extract questions and answers\n",
    "    for line in lines:\n",
    "        # Match questions (lines that start with \"## <number>.\")\n",
    "        question_match = question_pattern.match(line.strip())\n",
    "\n",
    "        if question_match:\n",
    "            # If we encounter a new question, save the previous question-answer pair (if any)\n",
    "            if current_question:\n",
    "                qa_list.append({\n",
    "                    \"question\": current_question.strip(),\n",
    "                    \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "                })\n",
    "            \n",
    "            # Store the new question and reset the answer collection\n",
    "            current_question = question_match.group(1).strip()  # Extract the question text\n",
    "            current_answer = []  # Reset for the new question\n",
    "        \n",
    "        # Match subsection headers (lines that start with \"####\"), these belong to the answer\n",
    "        elif subsection_pattern.match(line.strip()):\n",
    "            # Add subsections as part of the answer (e.g., \"#### Filter Methods\")\n",
    "            current_answer.append(f\"\\n\\n####{subsection_pattern.match(line.strip()).group(1)}\\n\\n\")\n",
    "        \n",
    "        else:\n",
    "            # Accumulate answer lines (anything after the question that isn't a new question header)\n",
    "            current_answer.append(line)\n",
    "\n",
    "    # Add the last question-answer pair after the loop\n",
    "    if current_question:\n",
    "        qa_list.append({\n",
    "            \"question\": current_question,\n",
    "            \"answer\": clean_answer(current_answer) if current_answer else \"\"\n",
    "        })\n",
    "    \n",
    "    return qa_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be4839b2-2866-4b43-908b-f7a507811212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now in main.md\n",
      "main\n",
      "Successfully parsed 33 questions and answers.\n",
      "\n",
      "Total questions parsed: 341\n"
     ]
    }
   ],
   "source": [
    "TOTAL_QUESTIONS_PARSED = 308\n",
    "\n",
    "file_name = github_mds_files[0]\n",
    "print(f\"Now in {file_name}\")\n",
    "concept_name = file_name.split('.')[0]\n",
    "print(concept_name)\n",
    "\n",
    "with open(os.path.join(github_mds_path, file_name), 'r') as f:\n",
    "    content = f.read()\n",
    "    qa_list = parse_questions_answers(content)\n",
    "\n",
    "with open(f\"questions_data/data/3_{concept_name}_parsed_questions.json\", 'w') as f:\n",
    "    json.dump(qa_list, f)\n",
    "\n",
    "print(f\"Successfully parsed {len(qa_list)} questions and answers.\")\n",
    "TOTAL_QUESTIONS_PARSED += len(qa_list)\n",
    "\n",
    "print()\n",
    "\n",
    "print(f\"Total questions parsed: {TOTAL_QUESTIONS_PARSED}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40479449-b809-4178-a0f8-b3ea1db306c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38ec0ef-1c03-4eb2-bf2a-da8df07cac9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_interviewer",
   "language": "python",
   "name": "llm_interviewer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
