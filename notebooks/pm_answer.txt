Q: Что такое обобщённые линейные модели (GLM) и как они отличаются от обычных линейных моделей?
A: Обобщённые линейные модели (GLM) представляют собой расширение обычных линейных моделей, позволяющее учитывать различные распределения целевой переменной. В отличие от обычных линейных моделей, где предполагается нормальное распределение ошибок, GLM могут использовать различные распределения, такие как биномиальное или пуассоновское, и включают функцию связи, которая связывает математическое ожидание целевой переменной с линейной комбинацией признаков.

Q: Какова основная мотивация использования вероятностных моделей в машинном обучении?
A: Основная мотивация заключается в том, что вероятностные модели позволяют учитывать неопределенность и случайность в данных, а также обеспечивают более гибкий подход к моделированию, позволяя использовать различные распределения для описания целевой переменной и ошибок.

Q: Какова роль функции связи в обобщённых линейных моделях?
A: Функция связи в обобщённых линейных моделях связывает математическое ожидание целевой переменной с линейной комбинацией признаков. Она позволяет преобразовать предсказания модели в вероятности или другие значения, соответствующие выбранному распределению.

Q: Почему в линейной регрессии предполагается, что ошибки имеют нормальное распределение?
A: Предположение о нормальном распределении ошибок в линейной регрессии позволяет использовать метод наименьших квадратов для оценки параметров модели, так как это приводит к минимизации суммы квадратов отклонений, что является удобным и хорошо обоснованным подходом в статистике.

Q: Каковы основные проблемы, связанные с мультиколлинеарностью в линейных моделях?
A: Мультиколлинеарность возникает, когда признаки в модели линейно зависимы или почти линейно зависимы. Это может привести к нестабильности оценок коэффициентов, затруднениям в интерпретации модели и увеличению погрешностей предсказаний.

Q: Что такое регуляризация и как она помогает в линейных моделях?
A: Регуляризация — это метод, который добавляет штраф за сложность модели в функцию потерь, что помогает предотвратить переобучение. В линейных моделях это может быть реализовано через L1- или L2-регуляризацию, что приводит к более устойчивым и интерпретируемым моделям.

Q: Какова основная идея метода максимального правдоподобия в контексте вероятностных моделей?
A: Основная идея метода максимального правдоподобия заключается в том, чтобы найти такие параметры модели, которые максимизируют вероятность наблюдаемых данных, что позволяет лучше подстраивать модель под реальные данные.

Q: Как логистическая регрессия использует вероятностный подход для классификации?
A: Логистическая регрессия использует вероятностный подход, предсказывая вероятность принадлежности объекта к положительному классу с помощью сигмоидной функции, которая преобразует линейную комбинацию признаков в значение от 0 до 1, что позволяет интерпретировать предсказания как вероятности.

Q: Почему важно использовать стохастический градиентный спуск при обучении моделей на больших данных?
A: Стохастический градиентный спуск позволяет эффективно обучать модели на больших данных, так как он обновляет параметры модели на основе небольших подвыборок (батчей), что значительно снижает вычислительные затраты и позволяет работать с данными, которые не помещаются в оперативную память.

Q: Как можно интерпретировать веса в линейной модели?
A: Веса в линейной модели можно интерпретировать как важность соответствующих признаков для предсказания целевой переменной. Положительный вес указывает на то, что увеличение значения признака приводит к увеличению предсказанного значения, тогда как отрицательный вес указывает на обратное.